{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Nadi -Bert Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53afc2f8a17a44caaa3dc5345c129af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab6a721e882e4395a186477efcc97053",
              "IPY_MODEL_f233b98a445d485b88445f95918fc7a4"
            ],
            "layout": "IPY_MODEL_3af48a97877e44a6ad3adebdb8ea6473"
          }
        },
        "3af48a97877e44a6ad3adebdb8ea6473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab6a721e882e4395a186477efcc97053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6518b9427194d86a08e4ad1bc814797",
            "max": 964,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b420e913de4434197c87bfd2c922dd9",
            "value": 964
          }
        },
        "f233b98a445d485b88445f95918fc7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2dc0dcb0bd244df8df982ab426021ab",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_758302ed058a496eb68f1af34bf071de",
            "value": " 964/964 [00:11&lt;00:00, 85.0B/s]"
          }
        },
        "1b420e913de4434197c87bfd2c922dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "d6518b9427194d86a08e4ad1bc814797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "758302ed058a496eb68f1af34bf071de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2dc0dcb0bd244df8df982ab426021ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56798de5b0b74106821e268b07a41dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b65fa5ef1a344a39c0f52a065845cdb",
              "IPY_MODEL_88e53e775e6d470aa5ac3ad4d9d9a916"
            ],
            "layout": "IPY_MODEL_03196d28102b46f98dcb4c052c1f162f"
          }
        },
        "03196d28102b46f98dcb4c052c1f162f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b65fa5ef1a344a39c0f52a065845cdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55dff5c4112c4cc4a47ae14c8e6c15e6",
            "max": 442514400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_437b3121a7c648aba5631506cd5182d5",
            "value": 442514400
          }
        },
        "88e53e775e6d470aa5ac3ad4d9d9a916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca0cf0a7f5864faab4e5d50f894272ca",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3432e2907108416cabef4ada4d8b0efe",
            "value": " 443M/443M [00:10&lt;00:00, 41.3MB/s]"
          }
        },
        "437b3121a7c648aba5631506cd5182d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "55dff5c4112c4cc4a47ae14c8e6c15e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3432e2907108416cabef4ada4d8b0efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca0cf0a7f5864faab4e5d50f894272ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y9UFtkimzvcg"
      },
      "source": [
        "\n",
        "# **Imporing Package**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gjrHcprGzmes",
        "colab": {},
        "outputId": "0ca01732-ceeb-4f28-8d2c-82b70438f49a"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install wget\n",
        "!pip install Barbar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/mms/anaconda3/lib/python3.7/site-packages (2.8.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /home/mms/anaconda3/lib/python3.7/site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /home/mms/anaconda3/lib/python3.7/site-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: filelock in /home/mms/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /home/mms/anaconda3/lib/python3.7/site-packages (from transformers) (1.12.42)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/mms/anaconda3/lib/python3.7/site-packages (from transformers) (2020.4.4)\n",
            "Requirement already satisfied: sacremoses in /home/mms/anaconda3/lib/python3.7/site-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: numpy in /home/mms/anaconda3/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
            "Requirement already satisfied: requests in /home/mms/anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/mms/anaconda3/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.42 in /home/mms/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (1.15.42)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/mms/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/mms/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /home/mms/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /home/mms/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /home/mms/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/mms/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/mms/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /home/mms/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/mms/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/mms/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.42->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /home/mms/anaconda3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.42->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: wget in /home/mms/anaconda3/lib/python3.7/site-packages (3.2)\n",
            "Requirement already satisfied: Barbar in /home/mms/anaconda3/lib/python3.7/site-packages (0.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gShEXBgJzmev",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import os.path\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertModel,BertPreTrainedModel\n",
        "from torch.utils.data import  random_split \n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,Dataset\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score,accuracy_score,recall_score,precision_score,matthews_corrcoef\n",
        "# from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import wget\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import sys\n",
        "import shutil\n",
        "from barbar import Bar\n",
        "seed_val = 96\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "# % matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKfeCeQv5jQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_path = './drive/My Drive/Colab/NLP/Nadi Shared Task/Data/'\n",
        "data_path = 'Data/'\n",
        "models_path = 'Models/'\n",
        "if not os.path.exists(data_path):    \n",
        "    os.makedirs(data_path)\n",
        "if not os.path.exists(models_path):    \n",
        "    os.makedirs(models_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-umhiKFaJRyQ",
        "colab": {}
      },
      "source": [
        "'''\n",
        "\n",
        "put your path to folder contains three files \n",
        "train_labeled.tsv\n",
        "dev_labeled.tsv\n",
        "unlabeled_data_10M.tsv\n",
        "\n",
        "this three files you could get them:\n",
        "1- share them from next google drive link and put them in your drive folder then put this folder path in data_path\n",
        "https://drive.google.com/open?id=1MUVnDWeozyb-pF3zxAF7kbtVkJviq1bc\n",
        "2- you can download them locally and put their folder path in data_path\n",
        "\n",
        "'''\n",
        "if not os.path.isfile(data_path + 'dev_labeled.tsv'):\n",
        "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1MgiF1_nmk3epPmTx8WX3L-o5L8LJ_Wx1' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1MgiF1_nmk3epPmTx8WX3L-o5L8LJ_Wx1\" -O dev_labeled.tsv && rm -rf /tmp/cookies.txt\n",
        "    shutil.move(\"dev_labeled.tsv\",data_path)\n",
        "    \n",
        "if not os.path.isfile(data_path + 'train_labeled.tsv'):\n",
        "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1m6uJQrvG1VAIRMmTgxQ5NgAUqVbUCzb6' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1m6uJQrvG1VAIRMmTgxQ5NgAUqVbUCzb6\" -O train_labeled.tsv && rm -rf /tmp/cookies.txt\n",
        "    shutil.move(\"train_labeled.tsv\",data_path)\n",
        "if not os.path.isfile(data_path + 'unlabeled_data_10M.tsv'):\n",
        "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1BCE5ctfi7sF9h8tuK5iVwqOQLAfurbXD' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1BCE5ctfi7sF9h8tuK5iVwqOQLAfurbXD\" -O unlabeled_data_10M.tsv && rm -rf /tmp/cookies.txt\n",
        "    shutil.move(\"unlabeled_data_10M.tsv\",data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IcJluXDh07Pv"
      },
      "source": [
        "# Use GPU if exists\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eoxjV4tjzmey",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b0e113da-0955-4a5b-de89-f0f79809df79"
      },
      "source": [
        "#re\n",
        "if torch.cuda.is_available():      \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU : \", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"Using CPU\")\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU :  GeForce RTX 2060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AOzEE-GE1NVQ"
      },
      "source": [
        "# Upload Data from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZG1J9Bruzme0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "ba7f7eb3-ba42-4dcb-c953-f1b60e8520e1"
      },
      "source": [
        "'''\n",
        "drive.mount('/content/drive')\n",
        "!unzip  \"/content/drive/My Drive/Colab/NLP/Nadi Shared Task/Data/NADI-2020_release_1.0.zip\"\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndrive.mount(\\'/content/drive\\')\\n!unzip  \"/content/drive/My Drive/Colab/NLP/Nadi Shared Task/Data/NADI-2020_release_1.0.zip\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rcuhjxVX1fsF"
      },
      "source": [
        "# Read Data using pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m2w9BrYrJSQv"
      },
      "source": [
        "Labels Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sl7drP9_Fcb4",
        "colab": {}
      },
      "source": [
        "labels_vocab = ['Iraq', 'Egypt', 'Morocco', 'Libya', 'United_Arab_Emirates', 'Mauritania', 'Saudi_Arabia', 'Bahrain', 'Syria', 'Djibouti', 'Lebanon', 'Oman', 'Palestine', 'Algeria', 'Somalia', 'Jordan', 'Tunisia', 'Kuwait', 'Yemen', 'Sudan', 'Qatar']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UKsWLeQtIx8u"
      },
      "source": [
        "Load Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fw2aPb6Czme5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "34d6573a-036f-41c6-8aea-1855ca717ee5"
      },
      "source": [
        "df_train = pd.read_csv(data_path + \"train_labeled.tsv\", delimiter='\\t',header=0, names=['tweet_ID', 'tweet_content', 'country_label', 'province_label'])\n",
        "df_train = df_train.drop(['tweet_ID', 'province_label'], axis=1)\n",
        "print('Number of training sentences: {:,}\\n'.format(df_train.shape[0]))\n",
        "df_train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 21,000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_content</th>\n",
              "      <th>country_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ø§Ù„ÙØ§Ø± Ø§Ù„Ø¹ÙˆØ± ÙŠØ´ÙˆÙ ÙÙ‚Ø· ÙƒÙŠØ³ÙŠ ÙˆÙ…Ø§ÙŠØ´ÙˆÙ Ù…Ø§ØªÙˆÙŠØ¯</td>\n",
              "      <td>Iraq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ÙŠ Ø¯ÙŠÙ†ÙŠÙŠÙŠÙŠ Ø±Ø¨Ù†Ø§ ÙŠØ³ØªØ±</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ø£Ø³Ø§Ø³Ø§Ù‹ Ù†Ø³Ø¨ÙƒÙ… Ù‚Ø°Ø± ÙˆÙ†Ø¬Ø³ Ø¨Ù„Ø§Ø´ ØªØªÙØ§Ø®Ø±ÙˆØ§ Ø¨Ù†Ø¬Ø§Ø³ØªÙƒÙ… ÙŠ...</td>\n",
              "      <td>Iraq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ù„ÙŠÙ’Ø³ÙØª ÙƒÙÙ„ Ø§Ù„Ù…ÙØ´ÙØ§Ø¹ÙØ±Ù ØªÙØ­Ù’ØªÙØ§Ø¬Ù Ø¥Ù„Ù‰ Ø­ÙØ¨ÙÙŠØ¨ Ø¨Ù...</td>\n",
              "      <td>Morocco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ù„Ø£ Ù†ÙŠ Ø­Ø§Ø¶Ø±Ù‡Ø§ Ù‡Ø°ÙŠ Ù„Ø§ÙŠÙ</td>\n",
              "      <td>Libya</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ø§Ù„Ù„Ù‡Ù… Ø§Ø´ÙÙŠ ÙƒÙ„ Ø´Ø®Øµ Ø¹Ø¨Ø§Ù„Ù‡ Ø§Ù„Ø¯Ù†ÙŠØ§ ÙˆØ§Ù‚ÙÙ‡ Ø¹Ù„ÙŠÙ‡</td>\n",
              "      <td>United_Arab_Emirates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ù‡ÙŠØªÙ‚Ø§Ù„ Ø¹Ù„ÙŠÙƒ Ù…Ø­Ø±ÙˆÙ‚ ÙˆÙ…Ø´ Ø¹Ø§Ø±Ù ØªØ¹Ù…Ù„ Ø²ÙŠÙ‡Ù… :D</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ÙˆØ§Ù„Ù‡ÙˆØ³Ø§Øª Ø§Ù„Ø²ÙŠÙ†Ù‡ Ø§Ø¨ÙŠØª Ù…Ø§Ø¬Ø¯ ÙŠØ§Ø³ÙŠÙ† Ø­Ù…Ø¯Ø§Ù„Ù„Ù‡ Ø¹ Ø³Ù„Ø§Ù…...</td>\n",
              "      <td>Iraq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ø§Ù†Ø§ Ù…Ù† Ø§Ù„Ù†Ø§Ø³ Ø§Ù„Ù…ØªØ®Ù„ÙØ© Ø§Ù„Ù„ÙŠ Ø¨ØªØ¹Ù…Ù„ ÙƒØ¯Ù‡ Ù„Ù„Ø£Ø³Ù Ø¨Ø³ ...</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ù…Ø´ÙƒÙ„Ø© Ù…ÙˆØ±ÙŠØªØ§Ù† Ø¹Ù†Ù‡Ø§ Ù…Ø§ØªÙ„ÙŠÙ†Ø§ Ù†ÙƒØ¯ Ù†ØµÙ†ÙÙˆÙ‡Ø§ Ù…Ù† Ø§Ù„Ø¯Ùˆ...</td>\n",
              "      <td>Mauritania</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet_content         country_label\n",
              "0           Ø§Ù„ÙØ§Ø± Ø§Ù„Ø¹ÙˆØ± ÙŠØ´ÙˆÙ ÙÙ‚Ø· ÙƒÙŠØ³ÙŠ ÙˆÙ…Ø§ÙŠØ´ÙˆÙ Ù…Ø§ØªÙˆÙŠØ¯                  Iraq\n",
              "1                                ÙŠ Ø¯ÙŠÙ†ÙŠÙŠÙŠÙŠ Ø±Ø¨Ù†Ø§ ÙŠØ³ØªØ±                 Egypt\n",
              "2  Ø£Ø³Ø§Ø³Ø§Ù‹ Ù†Ø³Ø¨ÙƒÙ… Ù‚Ø°Ø± ÙˆÙ†Ø¬Ø³ Ø¨Ù„Ø§Ø´ ØªØªÙØ§Ø®Ø±ÙˆØ§ Ø¨Ù†Ø¬Ø§Ø³ØªÙƒÙ… ÙŠ...                  Iraq\n",
              "3  Ù„ÙŠÙ’Ø³ÙØª ÙƒÙÙ„ Ø§Ù„Ù…ÙØ´ÙØ§Ø¹ÙØ±Ù ØªÙØ­Ù’ØªÙØ§Ø¬Ù Ø¥Ù„Ù‰ Ø­ÙØ¨ÙÙŠØ¨ Ø¨Ù...               Morocco\n",
              "4                              Ù„Ø£ Ù†ÙŠ Ø­Ø§Ø¶Ø±Ù‡Ø§ Ù‡Ø°ÙŠ Ù„Ø§ÙŠÙ                 Libya\n",
              "5          Ø§Ù„Ù„Ù‡Ù… Ø§Ø´ÙÙŠ ÙƒÙ„ Ø´Ø®Øµ Ø¹Ø¨Ø§Ù„Ù‡ Ø§Ù„Ø¯Ù†ÙŠØ§ ÙˆØ§Ù‚ÙÙ‡ Ø¹Ù„ÙŠÙ‡  United_Arab_Emirates\n",
              "6            Ù‡ÙŠØªÙ‚Ø§Ù„ Ø¹Ù„ÙŠÙƒ Ù…Ø­Ø±ÙˆÙ‚ ÙˆÙ…Ø´ Ø¹Ø§Ø±Ù ØªØ¹Ù…Ù„ Ø²ÙŠÙ‡Ù… :D                 Egypt\n",
              "7  ÙˆØ§Ù„Ù‡ÙˆØ³Ø§Øª Ø§Ù„Ø²ÙŠÙ†Ù‡ Ø§Ø¨ÙŠØª Ù…Ø§Ø¬Ø¯ ÙŠØ§Ø³ÙŠÙ† Ø­Ù…Ø¯Ø§Ù„Ù„Ù‡ Ø¹ Ø³Ù„Ø§Ù…...                  Iraq\n",
              "8  Ø§Ù†Ø§ Ù…Ù† Ø§Ù„Ù†Ø§Ø³ Ø§Ù„Ù…ØªØ®Ù„ÙØ© Ø§Ù„Ù„ÙŠ Ø¨ØªØ¹Ù…Ù„ ÙƒØ¯Ù‡ Ù„Ù„Ø£Ø³Ù Ø¨Ø³ ...                 Egypt\n",
              "9  Ù…Ø´ÙƒÙ„Ø© Ù…ÙˆØ±ÙŠØªØ§Ù† Ø¹Ù†Ù‡Ø§ Ù…Ø§ØªÙ„ÙŠÙ†Ø§ Ù†ÙƒØ¯ Ù†ØµÙ†ÙÙˆÙ‡Ø§ Ù…Ù† Ø§Ù„Ø¯Ùˆ...            Mauritania"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i2qn7IKEI1y5"
      },
      "source": [
        "Load Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7EliD7_KFUBV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "213a899d-9f63-48eb-8b9a-d5cfc07cc60b"
      },
      "source": [
        "df_test = pd.read_csv(data_path+\"dev_labeled.tsv\", delimiter='\\t',header=0, names=['tweet_ID', 'tweet_content', 'country_label', 'province_label'])\n",
        "df_test = df_test.drop(['tweet_ID', 'province_label'], axis=1)\n",
        "print('Number of training sentences: {:,}\\n'.format(df_test.shape[0]))\n",
        "df_test.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 4,957\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_content</th>\n",
              "      <th>country_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@Osama__zahrani Ø§ÙŠØ³ÙƒÙˆ Ù„Ø§Ø¹Ø¨ Ø§Ù„ÙŠÙˆÙ… :) Ø§Ø³ÙŠØ³Øª ÙˆÙ‡Ø¯Ù</td>\n",
              "      <td>Iraq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ø¨Ø¹Ø¯ ØµÙ„Ø§Ù‡ Ø§Ù„ÙØ¬Ø± Ø¨Ù‚Ø§</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø© ÙŠÙƒÙˆÙ† Ù…Ù† Ù†ØµÙŠØ¨ÙŠ</td>\n",
              "      <td>Algeria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø®Ù„ÙŠ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ ÙŠØ²ØºØ¨Ùƒ</td>\n",
              "      <td>Yemen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ÙƒÙ„ Ø­Ø§Ø¬Ø© Ù…Ø­Ø³ÙˆØ¨Ø© ÙŠØ§ Ø¬Ù…Ø§Ø¹Ø© ÙˆØ§Ù„Ù„Ù‡</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@kasimf Ø§Ù„Ù„Ù‡Ù… Ø¶ÙŠÙ‚ Ø¹Ù„ÙŠÙ‡ Ø£Ù†ÙØ§Ø³Ù‡ ÙˆØ¹Ø³Ø± Ù…ÙŠØªØªÙ‡ Ø¥Ù„Ù‰ Ø£...</td>\n",
              "      <td>Saudi_Arabia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ÙŠØ¹Ù†ÙŠ Ù…Ø§ ÙŠØ­ØªØ§Ø¬ Ù†Ù„Ø¨Ø³ Ø«Ù‚ÙŠÙ„</td>\n",
              "      <td>Syria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(ÙˆÙ„Ø¦Ù† Ø³Ø£Ù„ØªÙ‡Ù… Ù…Ù† Ø®Ù„Ù‚Ù‡Ù… Ù„ÙŠÙ‚ÙˆÙ„Ù† Ø§Ù„Ù„Ù‡ ÙØ£Ù†Ù‰ ÙŠØ¤ÙÙƒÙˆÙ†)...</td>\n",
              "      <td>Egypt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ø¢Ø³ØªÙˆØ¯Ø¹Ùƒ ÙŠØ§ Ø±Ø¨ÙŠ Ø´Ø®ØµØ§Ù‹ ÙŠÙ†Ø¨Ø¶ ÙÙŠ Ù‚Ù„Ø¨ÙŠ ÙƒÙ„ Ù…Ø±Ù‡ ØŒ ÙˆÙ„Ø§...</td>\n",
              "      <td>United_Arab_Emirates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ù‚ÙÙ„ Ù„ÙÙ‘Ù† ÙŠÙØµÙÙŠØ¨ÙÙ†ÙØ§ Ø¥ÙÙ„ÙÙ‘Ø§ Ù…ÙØ§ ÙƒÙØªÙØ¨Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù ...</td>\n",
              "      <td>Iraq</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet_content         country_label\n",
              "0     @Osama__zahrani Ø§ÙŠØ³ÙƒÙˆ Ù„Ø§Ø¹Ø¨ Ø§Ù„ÙŠÙˆÙ… :) Ø§Ø³ÙŠØ³Øª ÙˆÙ‡Ø¯Ù                  Iraq\n",
              "1                                 Ø¨Ø¹Ø¯ ØµÙ„Ø§Ù‡ Ø§Ù„ÙØ¬Ø± Ø¨Ù‚Ø§                 Egypt\n",
              "2                Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø© ÙŠÙƒÙˆÙ† Ù…Ù† Ù†ØµÙŠØ¨ÙŠ               Algeria\n",
              "3               Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø®Ù„ÙŠ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ ÙŠØ²ØºØ¨Ùƒ                 Yemen\n",
              "4                      ÙƒÙ„ Ø­Ø§Ø¬Ø© Ù…Ø­Ø³ÙˆØ¨Ø© ÙŠØ§ Ø¬Ù…Ø§Ø¹Ø© ÙˆØ§Ù„Ù„Ù‡                 Egypt\n",
              "5  @kasimf Ø§Ù„Ù„Ù‡Ù… Ø¶ÙŠÙ‚ Ø¹Ù„ÙŠÙ‡ Ø£Ù†ÙØ§Ø³Ù‡ ÙˆØ¹Ø³Ø± Ù…ÙŠØªØªÙ‡ Ø¥Ù„Ù‰ Ø£...          Saudi_Arabia\n",
              "6                            ÙŠØ¹Ù†ÙŠ Ù…Ø§ ÙŠØ­ØªØ§Ø¬ Ù†Ù„Ø¨Ø³ Ø«Ù‚ÙŠÙ„                 Syria\n",
              "7  (ÙˆÙ„Ø¦Ù† Ø³Ø£Ù„ØªÙ‡Ù… Ù…Ù† Ø®Ù„Ù‚Ù‡Ù… Ù„ÙŠÙ‚ÙˆÙ„Ù† Ø§Ù„Ù„Ù‡ ÙØ£Ù†Ù‰ ÙŠØ¤ÙÙƒÙˆÙ†)...                 Egypt\n",
              "8  Ø¢Ø³ØªÙˆØ¯Ø¹Ùƒ ÙŠØ§ Ø±Ø¨ÙŠ Ø´Ø®ØµØ§Ù‹ ÙŠÙ†Ø¨Ø¶ ÙÙŠ Ù‚Ù„Ø¨ÙŠ ÙƒÙ„ Ù…Ø±Ù‡ ØŒ ÙˆÙ„Ø§...  United_Arab_Emirates\n",
              "9  Ù‚ÙÙ„ Ù„ÙÙ‘Ù† ÙŠÙØµÙÙŠØ¨ÙÙ†ÙØ§ Ø¥ÙÙ„ÙÙ‘Ø§ Ù…ÙØ§ ÙƒÙØªÙØ¨Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù ...                  Iraq"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PV9DT8ZiI9gj"
      },
      "source": [
        "Load Unlabeled Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3ulPqYVQen7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "311b4dae-e759-4b4e-9f52-929af3920846"
      },
      "source": [
        "df_unlabeled = pd.read_csv(data_path+\"unlabeled_data_10M.tsv\", delimiter='\\t',header=0, names=['tweet_ID', 'tweet_content'])\n",
        "\n",
        "df_unlabeled = df_unlabeled.drop(['tweet_ID'], axis=1)\n",
        "print('Number of training sentences: {:,}\\n'.format(df_unlabeled.shape[0]))\n",
        "df_unlabeled.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 9,549,500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @Almajlliss: ÙˆØ²ÙŠØ± Ø§Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„Ù†Ø§Ø¦Ø¨ Ø¯.Ù…Ø­Ù…Ø¯ Ø§Ù„...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø®Ù…Ø³Ø© Ù„Ù„Ù†Ø¬Ø§Ø­ : Ø§Ù„ØªØ±ÙƒÙŠØ²ØŒ Ø§Ù„ØªÙ…ÙŠØ²ØŒ Ø§Ù„ØªÙ†Ø¸...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @mn9oorr_77: â € â €â €â €â €â €â € ØªÙ€ÙØºØ§Ø± Ù…Ù€ÙÙ† Ù…ÙÙ€ÙŠÙ†ÙØŒÙˆØ£...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Mohamed__Eissa: Ù‚Ù„Ø¨ÙŠ ÙŠØ¯Ù‚ \"ÙƒØµØ±Ø®Ø§Øª Ø·Ø§Ù„Ø¨\" Ùˆ Ù‚...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ø¨Ø¹Ø¶ Ø§Ù„ØºÙŠØ§Ø¨ ÙŠØ¹Ù„Ù…Ùƒ ÙƒÙŠÙ ØªØ´ØªØ§Ù‚ ØŒ ÙˆØ¨Ø¹Ø¶ Ø§Ù„ØºÙŠØ§Ø¨ ÙŠØ¹Ù„Ù…Ùƒ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ø§ÙˆÙ‡ Ù†Ø³ÙŠØª Ø§Ù‚ÙˆÙ„ Ø§Ù…Ø³ÙŠÙ†Ø§ ÙˆØ§Ù…Ø³Ù‰ Ø§Ù„Ù…Ù„Ùƒ Ù„Ù„Ù‡ ğŸ˜Š</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RT @b_p_QQQ: Ù‡Ø°ÙŠ Ù‡ÙŠ Ø§Ù„Ø¯Ù†ÙŠØ§ ØªØ¬Ø§Ø±Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙˆÙ… ØªØ¹Ø·...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RT @M__I__K__A1: Ø¹Ù† Ø§Ù„Ù„Ø­Ø¸Ù‡ Ø§Ù„Ø­Ù„ÙˆÙ‡ Ø§Ù„Ù„Ù‰ Ø¨ØªØºÙ…Ø¶ Ù...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4-ÙØ§Ù„Ø¥Ù†Ø³Ø§Ù† Ù…Ø³Ø¤ÙˆÙ„ ÙˆÙ…Ø­Ø§Ø³Ø¨ Ø¹Ù† ÙƒÙ„ Ù…Ø§ÙŠØªÙÙˆÙ‡ Ø¨Ù‡ ÙˆØ§Ù„Ù…Øµ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RT @FAHAD_BN_KHALID: Ø§Ø®ÙŠ Ø§Ù„ØºØ§Ù„ÙŠ Ø±Ø¦ÙŠØ³Ù†Ø§ Ø§Ù„Ø°Ù‡Ø¨ÙŠ ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       tweet_content\n",
              "0  RT @Almajlliss: ÙˆØ²ÙŠØ± Ø§Ù„ØªØ±Ø¨ÙŠØ© ÙˆØ§Ù„Ù†Ø§Ø¦Ø¨ Ø¯.Ù…Ø­Ù…Ø¯ Ø§Ù„...\n",
              "1  Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„Ø®Ù…Ø³Ø© Ù„Ù„Ù†Ø¬Ø§Ø­ : Ø§Ù„ØªØ±ÙƒÙŠØ²ØŒ Ø§Ù„ØªÙ…ÙŠØ²ØŒ Ø§Ù„ØªÙ†Ø¸...\n",
              "2  RT @mn9oorr_77: â € â €â €â €â €â €â € ØªÙ€ÙØºØ§Ø± Ù…Ù€ÙÙ† Ù…ÙÙ€ÙŠÙ†ÙØŒÙˆØ£...\n",
              "3  RT @Mohamed__Eissa: Ù‚Ù„Ø¨ÙŠ ÙŠØ¯Ù‚ \"ÙƒØµØ±Ø®Ø§Øª Ø·Ø§Ù„Ø¨\" Ùˆ Ù‚...\n",
              "4  Ø¨Ø¹Ø¶ Ø§Ù„ØºÙŠØ§Ø¨ ÙŠØ¹Ù„Ù…Ùƒ ÙƒÙŠÙ ØªØ´ØªØ§Ù‚ ØŒ ÙˆØ¨Ø¹Ø¶ Ø§Ù„ØºÙŠØ§Ø¨ ÙŠØ¹Ù„Ù…Ùƒ...\n",
              "5             Ø§ÙˆÙ‡ Ù†Ø³ÙŠØª Ø§Ù‚ÙˆÙ„ Ø§Ù…Ø³ÙŠÙ†Ø§ ÙˆØ§Ù…Ø³Ù‰ Ø§Ù„Ù…Ù„Ùƒ Ù„Ù„Ù‡ ğŸ˜Š\n",
              "6  RT @b_p_QQQ: Ù‡Ø°ÙŠ Ù‡ÙŠ Ø§Ù„Ø¯Ù†ÙŠØ§ ØªØ¬Ø§Ø±Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙˆÙ… ØªØ¹Ø·...\n",
              "7  RT @M__I__K__A1: Ø¹Ù† Ø§Ù„Ù„Ø­Ø¸Ù‡ Ø§Ù„Ø­Ù„ÙˆÙ‡ Ø§Ù„Ù„Ù‰ Ø¨ØªØºÙ…Ø¶ Ù...\n",
              "8  4-ÙØ§Ù„Ø¥Ù†Ø³Ø§Ù† Ù…Ø³Ø¤ÙˆÙ„ ÙˆÙ…Ø­Ø§Ø³Ø¨ Ø¹Ù† ÙƒÙ„ Ù…Ø§ÙŠØªÙÙˆÙ‡ Ø¨Ù‡ ÙˆØ§Ù„Ù…Øµ...\n",
              "9  RT @FAHAD_BN_KHALID: Ø§Ø®ÙŠ Ø§Ù„ØºØ§Ù„ÙŠ Ø±Ø¦ÙŠØ³Ù†Ø§ Ø§Ù„Ø°Ù‡Ø¨ÙŠ ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KN9k0w07XMdr",
        "colab": {}
      },
      "source": [
        "df_corpus = df_train.tweet_content.append(df_test.tweet_content).append(df_unlabeled.tweet_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qxuZQZUkXxZ4",
        "colab": {}
      },
      "source": [
        "print(len(df_corpus))\n",
        "df_corpus.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSx3SR7r5jRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rx6Nn0d_zme7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "2623acc6-b8b5-4773-87b7-49901617e00a"
      },
      "source": [
        "'''\n",
        "dframe = pd.DataFrame()\n",
        "for i in range(1,15):\n",
        "  path = \"./drive/My Drive/Colab/NLP/Nadi Shared Task/Data/unlabeled_10M_\"+str(i)+\".tsv\"\n",
        "  t = pd.read_csv(path, delimiter='\\t',header=0, names=['tweet_ID', 'tweet_content'])\n",
        "  print(\"path = \",path,\"\\nlength = \",len(t))\n",
        "  dframe = dframe.append(t)\n",
        "print(len(dframe))\n",
        "# dframe.tail()\n",
        "#3,635,600\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndframe = pd.DataFrame()\\nfor i in range(1,15):\\n  path = \"./drive/My Drive/Colab/NLP/Nadi Shared Task/Data/unlabeled_10M_\"+str(i)+\".tsv\"\\n  t = pd.read_csv(path, delimiter=\\'\\t\\',header=0, names=[\\'tweet_ID\\', \\'tweet_content\\'])\\n  print(\"path = \",path,\"\\nlength = \",len(t))\\n  dframe = dframe.append(t)\\nprint(len(dframe))\\n# dframe.tail()\\n#3,635,600\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "06fY76i4NWqi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "91016005-f4bf-4fea-e56d-386f71ccc4b5"
      },
      "source": [
        "'''\n",
        "shutil.move(\"unlabeled_data_10M.tsv\",\"./drive/My Drive/Colab/NLP/Nadi Shared Task/Data\")\n",
        "shutil.move(\"./NADI_release/dev_labeled.tsv\",\"./drive/My Drive/Colab/NLP/Nadi Shared Task/Data\")\n",
        "shutil.move(\"./NADI_release/train_labeled.tsv\",\"./drive/My Drive/Colab/NLP/Nadi Shared Task/Data\")\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nshutil.move(\"unlabeled_data_10M.tsv\",\"./drive/My Drive/Colab/NLP/Nadi Shared Task/Data\")\\nshutil.move(\"./NADI_release/dev_labeled.tsv\",\"./drive/My Drive/Colab/NLP/Nadi Shared Task/Data\")\\nshutil.move(\"./NADI_release/train_labeled.tsv\",\"./drive/My Drive/Colab/NLP/Nadi Shared Task/Data\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_5s2f85k1plO"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EDH8iHD37jlV",
        "colab": {}
      },
      "source": [
        "#From Moustafa Tohamy\n",
        "\n",
        "arabic_punctuations = '''`Ã·Ã—Ø›<>_()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
        "english_punctuations = string.punctuation\n",
        "punctuations_list = arabic_punctuations + english_punctuations\n",
        "\n",
        "arabic_diacritics = re.compile(\"\"\"\n",
        "                             Ù‘    | # Tashdid\n",
        "                             Ù    | # Fatha\n",
        "                             Ù‹    | # Tanwin Fath\n",
        "                             Ù    | # Damma\n",
        "                             ÙŒ    | # Tanwin Damm\n",
        "                             Ù    | # Kasra\n",
        "                             Ù    | # Tanwin Kasr\n",
        "                             Ù’    | # Sukun\n",
        "                             Ù€     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)\n",
        "\n",
        "def remove_links(text):\n",
        "  text = re.sub(r'http\\S+', '', text)\n",
        "  return text\n",
        "\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\", text)\n",
        "    text = re.sub(\"Ù‰\", \"ÙŠ\", text)\n",
        "    text = re.sub(\"Ø¤\", \"Ø¡\", text)\n",
        "    text = re.sub(\"Ø¦\", \"Ø¡\", text)\n",
        "    text = re.sub(\"Ø©\", \"Ù‡\", text)\n",
        "    text = re.sub(\"Ú¯\", \"Ùƒ\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_diacritics(text):\n",
        "    text = re.sub(arabic_diacritics, '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)\n",
        "\n",
        "\n",
        "def remove_repeating_char(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "def pre_process_document(text):\n",
        "  text = remove_links(text)\n",
        "  text = remove_punctuations(text)\n",
        "  # text = remove_diacritics(text)\n",
        "  text = remove_repeating_char(text)\n",
        "  return text\n",
        "\n",
        "pre_process_corpus = np.vectorize(pre_process_document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TarFHJMjDVth"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XgeawnzJzmfg",
        "colab": {}
      },
      "source": [
        "def save_model(model,epoch,model_type):\n",
        "  output_file = './saved_'+model_type+'_epoch'+str(epoch)+'.txt'\n",
        "  print(\"Saving model to %s\" % output_file)\n",
        "  torch.save(model.state_dict(), output_file)\n",
        "  shutil.move(output_file,models_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AuWhQSZqEoEC",
        "colab": {}
      },
      "source": [
        "def load_model(model,epoch,model_type):\n",
        "  path = models_path + 'saved_'+model_type+'_epoch'+str(epoch)+'.txt'\n",
        "  print(\"Loading model from %s\" % path)\n",
        "  model.load_state_dict(torch.load(path))\n",
        "  return model\n",
        "# model_embed_pretrained.load_state_dict(torch.load(path))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlGLT_pl5jRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_asafaya(model,models_path):\n",
        "    print(\"Saving model to %s\" % models_path)\n",
        "    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "    # They can then be reloaded using `from_pretrained()`\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "    model_to_save.save_pretrained(models_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "66gHxYLxzmff",
        "colab": {}
      },
      "source": [
        "def show_model_parameters(model):\n",
        "  # Get all of the model's parameters as a list of tuples.\n",
        "  params = list(model.named_parameters())\n",
        "\n",
        "  print('# of parameters = \\n',len(params))\n",
        "  print('==== Embedding Layer ====\\n')\n",
        "  for p in params[0:5]:\n",
        "      print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "  print('\\n==== First Transformer ====\\n')\n",
        "  for p in params[5:21]:\n",
        "      print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "  print('\\n==== Output Layer ====\\n')\n",
        "  for p in params[-4:]:\n",
        "      print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UHQ_CGzmt13h",
        "colab": {}
      },
      "source": [
        "def prepare_data(dataset,train_size,batch_size):\n",
        "  train_size = int(train_size * len(dataset)) #99% train_size\n",
        "  val_size = len(dataset) - train_size #1% val size\n",
        "  train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "  train_dataloader = DataLoader(train_dataset,sampler = RandomSampler(train_dataset),batch_size = batch_size)\n",
        "  validation_dataloader = DataLoader(val_dataset,sampler = RandomSampler(val_dataset),batch_size = batch_size)\n",
        "  print('training samples',len(train_dataset))\n",
        "  print('validation samples',len(val_dataset))\n",
        "  return train_dataloader,validation_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GOgdmdvPzmfj",
        "colab": {}
      },
      "source": [
        "def training_model(model,model_type,train_dataloader,validation_dataloader,epochs):\n",
        "  training_loss = []\n",
        "  validation_loss = []\n",
        "  validation_acc = []\n",
        "  optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8 )\n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "  warmup_steps = 0 \n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = warmup_steps,num_training_steps = total_steps)\n",
        "  start_time = time.time()\n",
        "  for epoch in range(epochs):\n",
        "      total_train_loss = 0\n",
        "      model.train()\n",
        "      print('Epoch: {}'.format(epoch+1))\n",
        "      for step, batch in enumerate(Bar(train_dataloader)):\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "          model.zero_grad()\n",
        "          loss, logits = model(b_input_ids,token_type_ids=None, attention_mask=b_input_mask,labels=b_labels) #it computes loss function so it takes labels\n",
        "          total_train_loss += loss.item()\n",
        "          loss.backward()\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "\n",
        "      avg_train_loss = total_train_loss / len(train_dataloader)  \n",
        "\n",
        "      model.eval()\n",
        "      save_model(model,epoch+1,model_type)\n",
        "      total_eval_accuracy = 0\n",
        "      total_eval_loss = 0\n",
        "      nb_eval_steps = 0\n",
        "      print(\"Validation\")\n",
        "      for batch in validation_dataloader:\n",
        "          b_input_ids = batch[0].to(device)\n",
        "          b_input_mask = batch[1].to(device)\n",
        "          b_labels = batch[2].to(device)\n",
        "\n",
        "          with torch.no_grad():        \n",
        "            (loss, logits) = model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)\n",
        "            total_eval_loss += loss.item()\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "\n",
        "      avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "      print(\"Validation Loss :\", avg_val_loss )\n",
        "      training_loss.append(avg_train_loss)\n",
        "      validation_loss.append(avg_val_loss)\n",
        "\n",
        "  elapsed_time = time.time() - start_time\n",
        "  print(\"Done\")\n",
        "  print(\"Total training took :\",str(datetime.timedelta(seconds=int(round((elapsed_time))))))\n",
        "  return model,training_loss,validation_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cH5Ap3_glpQc"
      },
      "source": [
        "# Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ci4N140Yluv1",
        "colab": {}
      },
      "source": [
        "class Transform_preprocess():\n",
        "  def __call__(self,x):\n",
        "    out = pre_process_corpus([x])[0]\n",
        "    return out\n",
        "class Transform_to_trigram():\n",
        "  def __call__(self,x):\n",
        "    out = \" \".join(re.findall('...|..$|.$',x.replace(\" \",\"\")))\n",
        "    return out\n",
        "class Transform_to_bigram():\n",
        "  def __call__(self,x):\n",
        "    out = \" \".join(re.findall('..|.$',x.replace(\" \",\"\")))\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zlSqIRqcAeYP"
      },
      "source": [
        "# Word Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Nr7L9PP411ft"
      },
      "source": [
        "## Corpus Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yo5mdaJ4zmfA",
        "colab": {}
      },
      "source": [
        "class CorpusDataset(Dataset):\n",
        "    def __init__(self,corpus,tokenizer,context_size = 2,preprocess=None,transform = None):\n",
        "        self.tokens = []      \n",
        "        self.dataset = []\n",
        "        self.input_ids = []\n",
        "        self.attention_masks = []\n",
        "        self.output_ids = []\n",
        "        self.preprocess = preprocess\n",
        "        self.transform = transform\n",
        "        self.tokenizer = tokenizer\n",
        "        self.context_size = context_size\n",
        "        print(\"Tokenizer Loading\")\n",
        "        self.tokenize_corpus(corpus)\n",
        "        print(\"Context vector Loading\")\n",
        "        self.context_vector()\n",
        "        print(\"Features Loading\")\n",
        "        self.get_inputs_features()\n",
        "    def tokenize_corpus(self,corpus):   \n",
        "        loading_length = len(corpus)\n",
        "        print(\"Length = \",loading_length)\n",
        "        for iter,sent in enumerate(corpus):\n",
        "          if(self.preprocess):\n",
        "            sent =self.preprocess(sent)\n",
        "          if(self.transform):\n",
        "            sent = self.transform(sent)\n",
        "          self.tokens.append(sent.split())\n",
        "          if(iter % 100000 == 0):\n",
        "              loading = int(iter*100/loading_length)\n",
        "              print(\"Loading Tokenizer:\",loading,\"%\")\n",
        "\n",
        "    def context_vector(self):\n",
        "        loading_length = len(self.tokens)\n",
        "        print(\"Length = \",loading_length)\n",
        "        for iter,sentence in enumerate(self.tokens):\n",
        "          for i in range(0,len(sentence)): #min len(sentence) = 2\n",
        "              context = []\n",
        "              for j in reversed(range(1,self.context_size+1)):\n",
        "                  if((i-j) >= 0): #if sentence[i-j] != null\n",
        "                      context.append(sentence[i-j])\n",
        "              for j in range(1,self.context_size+1):\n",
        "                  if((i+j) < len(sentence)): #if sentence[i+j] != null\n",
        "                      context.append(sentence[i+j])\n",
        "              target = sentence[i]\n",
        "\n",
        "              if(len(context) == 0 or len(target.split()) == 0): \n",
        "                continue\n",
        "              if(self.transform):\n",
        "                self.dataset.append([self.transform(\"\".join([input_word for input_word in context])),target])\n",
        "              else:\n",
        "                self.dataset.append([\" \".join([input_word for input_word in context]),target])\n",
        "          if(iter % 100000 == 0):\n",
        "              loading = int(iter*100/loading_length)  \n",
        "              print(\"Loading Context vector:\",loading,\"%\")\n",
        "\n",
        "    \n",
        "    def show_dataset(self):\n",
        "        for input_word,output_word in self.dataset:\n",
        "            print(self.idx2word[input_word],self.idx2word[output_word])\n",
        "\n",
        "    def get_inputs_features(self):\n",
        "      loading_length = len(self.dataset)\n",
        "      print(\"Length = \",loading_length)\n",
        "      input_ids = []\n",
        "      output_ids = []\n",
        "      attention_masks = []\n",
        "      for step,item in enumerate(self.dataset):\n",
        "        sentences,label = item\n",
        "        input_dict = self.tokenizer.encode_plus(\n",
        "              sentences,                      # Sentence to encode.\n",
        "              add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "              max_length = 16,           # Pad & truncate all sentences.\n",
        "              pad_to_max_length = True,\n",
        "              return_attention_mask = True,   # Construct attn. masks.\n",
        "              return_tensors = 'pt',     # Return pytorch tensors.\n",
        "          )\n",
        "        output_dict = self.tokenizer.encode_plus(\n",
        "              label,                      # Sentence to encode.\n",
        "              add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n",
        "              max_length = 1,           # Pad & truncate all sentences.\n",
        "              pad_to_max_length = False,\n",
        "              return_attention_mask = False   # Construct attn. masks.\n",
        "              # return_tensors = 'pt',     # Return pytorch tensors.\n",
        "          )\n",
        "        self.input_ids.append(input_dict['input_ids'])\n",
        "        self.attention_masks.append(input_dict['attention_mask'])\n",
        "        if(len(output_dict['input_ids']) == 0):\n",
        "          output_dict['input_ids'].append(0)\n",
        "        self.output_ids.append(torch.tensor(output_dict['input_ids']))\n",
        "        if(step % 100000 == 0):\n",
        "            loading = int(step*100/loading_length)\n",
        "            print(\"Loading Features:\",loading,\"%\")\n",
        "\n",
        "      \n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "      return self.input_ids[idx][0],self.attention_masks[idx][0],self.output_ids[idx][0]\n",
        "            \n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gyCOSSSmBSTV"
      },
      "source": [
        "## Bert Embdding Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5Tk_G4w5zmfK",
        "colab": {}
      },
      "source": [
        "class BertEmbedding(torch.nn.Module):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    \"\"\"\n",
        "    def __init__(self,path=\"asafaya/bert-base-arabic\" ):\n",
        "        super(BertEmbedding, self).__init__()\n",
        "        self.model_config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "          num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "        self.bert = BertModel.from_pretrained(path)\n",
        "        self.dropout = torch.nn.Dropout(self.model_config.hidden_dropout_prob)\n",
        "        self.embedding2 = torch.nn.Linear(self.model_config.hidden_size, self.model_config.vocab_size_or_config_json_file)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _,pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.embedding2(pooled_output)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss()\n",
        "            #Cross Entropy input.shape= [batch_size,num_labels] ,labels.shape = [batch_size]\n",
        "            loss = loss_fct(logits,labels.view(-1))\n",
        "        return loss,logits\n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True\n",
        "        \n",
        "    def save_pretrained(self,path):\n",
        "        self.bert.save_pretrained(path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlbMgTDR5jRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_tokenizer = models_path+\"tokenizer/\"\n",
        "if not os.path.exists(path_tokenizer):    \n",
        "    os.makedirs(path_tokenizer)\n",
        "    tokenizer = BertTokenizer.from_pretrained('asafaya/bert-base-arabic', do_lower_case=True)\n",
        "    tokenizer.save_pretrained(path_tokenizer)\n",
        "else:\n",
        "    tokenizer = BertTokenizer.from_pretrained(path_tokenizer, do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWPYvelx5jRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_asafaya = models_path+\"asafaya_arabic_model/\"\n",
        "if not os.path.exists(path_asafaya):    \n",
        "    os.makedirs(path_asafaya)\n",
        "    model_embed = BertEmbedding('asafaya/bert-base-arabic')\n",
        "    model_embed.save_pretrained(path_asafaya)\n",
        "else:\n",
        "    model_embed = BertEmbedding(path_asafaya)\n",
        "    \n",
        "# model_embed.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IKoA4BANzmfO",
        "colab": {}
      },
      "source": [
        "# load model\n",
        "embed_epoch = 1\n",
        "model_embed = load_model(model_embed,embed_epoch,'embed')\n",
        "model_embed.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nlhBq4dPu19i",
        "colab": {}
      },
      "source": [
        "# corpus = pre_process_corpus(df_corpus.values)\n",
        "dataset_cbow = CorpusDataset(df_corpus.values,tokenizer,context_size = 10,preprocess=Transform_preprocess(),transform = None)\n",
        "print(\"Dataset training samples :\",len(dataset_cbow))\n",
        "print(dataset_cbow[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-51uR0LYcx3H",
        "colab": {}
      },
      "source": [
        "del df_unlabeled\n",
        "del df_corpus\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zGPvU1gVuX7X",
        "colab": {}
      },
      "source": [
        "train_dataloader ,validation_dataloader = prepare_data(dataset_cbow,0.99,64) #dataset_cbow "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2KX-VcDjxZSx",
        "colab": {}
      },
      "source": [
        "model_embed,training_loss_embed,validation_loss_embed  = training_model(model_embed,\"embed\",train_dataloader,validation_dataloader,epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UCmfDOBQBZ3F"
      },
      "source": [
        "# Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_d4BGu6NBffN"
      },
      "source": [
        "## Nadi Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jAf7js2kzmfE",
        "colab": {}
      },
      "source": [
        "class dataset_nadi():\n",
        "  def __init__(self,sentences,labels,labels_vocab,tokenizer,preprocess=None,transform=None):\n",
        "    self.preprocess = preprocess\n",
        "    self.transform=transform\n",
        "    self.sentences = sentences\n",
        "    self.labels = labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.labels_vocab = labels_vocab\n",
        "    self.label2idx = self.label2idx()\n",
        "    self.idx2label = self.idx2label()\n",
        "    self.labels_indices = [self.label2idx[label] for label in self.labels]\n",
        "    self.max_length,self.max_len_word = self.get_max_length()\n",
        "    self.inputs_id,self.attention_masks = self.get_inputs_features()\n",
        "\n",
        "  def label2idx(self):\n",
        "    return {w:i for i,w in enumerate(self.labels_vocab)}\n",
        "\n",
        "  def idx2label(self):\n",
        "    return {i:w for i,w in enumerate(self.labels_vocab)}\n",
        "\n",
        "  def get_max_length(self):\n",
        "    max_len = 0.\n",
        "    max_len_idx = 0\n",
        "    for i,sent in enumerate(self.sentences):\n",
        "        input_ids = self.tokenizer.encode(sent, add_special_tokens=True)\n",
        "        if(len(input_ids) > max_len):\n",
        "          max_len = len(input_ids)\n",
        "          max_len_idx = i\n",
        "    return max_len,self.sentences[max_len_idx]\n",
        "\n",
        "  def get_inputs_features(self):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for sent in self.sentences:\n",
        "      if(self.preprocess):\n",
        "        sent =self.preprocess(sent)\n",
        "      if(self.transform):\n",
        "        sent = self.transform(sent)\n",
        "      encoded_dict = self.tokenizer.encode_plus(\n",
        "            sent,                      # Sentence to encode.\n",
        "            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "            max_length = 200,           # Pad & truncate all sentences.\n",
        "            pad_to_max_length = True,\n",
        "            return_attention_mask = True,   # Construct attn. masks.\n",
        "            return_tensors = 'pt',     # Return pytorch tensors.\n",
        "        )\n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "    return input_ids,attention_masks\n",
        "\n",
        "  # def get_bert_input_format(self):\n",
        "      \n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "      input_ids = self.inputs_id[idx][0]\n",
        "      attention_masks = self.attention_masks[idx][0]\n",
        "      labels_ids = torch.tensor(self.labels_indices[idx])\n",
        "      return input_ids,attention_masks,labels_ids\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b6wQLEY9Blhd"
      },
      "source": [
        "## Bert Nadi Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kULnrJhhzmfM",
        "colab": {}
      },
      "source": [
        "class Bert_Nadi_Task(torch.nn.Module):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    \"\"\"\n",
        "    def __init__(self,Model=None,num_labels =  21):\n",
        "        super(Bert_Nadi_Task, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        model_config = BertConfig(vocab_size_or_config_json_file=32000, hidden_size=768,\n",
        "          num_hidden_layers=12, num_attention_heads=12, intermediate_size=3072)\n",
        "        self.bert = Model\n",
        "        self.norm = torch.nn.LayerNorm((model_config.vocab_size_or_config_json_file,), eps=model_config.layer_norm_eps, elementwise_affine=True)\n",
        "        self.tanh = torch.nn.Tanh()\n",
        "        self.dropout = torch.nn.Dropout(model_config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(model_config.vocab_size_or_config_json_file, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _,logits = self.bert(input_ids, token_type_ids, attention_mask)\n",
        "        norm_output = self.norm(logits)\n",
        "        out = self.dropout(self.tanh(norm_output))\n",
        "        logits = self.classifier(out)\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss()\n",
        "            #Cross Entropy input.shape= [batch_size,num_labels] ,labels.shape = [batch_size]\n",
        "            loss = loss_fct(logits,labels.view(-1))\n",
        "        #test\n",
        "        return loss,logits\n",
        "\n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zq9dOGu3zmfP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "53afc2f8a17a44caaa3dc5345c129af9",
            "3af48a97877e44a6ad3adebdb8ea6473",
            "ab6a721e882e4395a186477efcc97053",
            "f233b98a445d485b88445f95918fc7a4",
            "1b420e913de4434197c87bfd2c922dd9",
            "d6518b9427194d86a08e4ad1bc814797",
            "758302ed058a496eb68f1af34bf071de",
            "f2dc0dcb0bd244df8df982ab426021ab",
            "56798de5b0b74106821e268b07a41dc1",
            "03196d28102b46f98dcb4c052c1f162f",
            "3b65fa5ef1a344a39c0f52a065845cdb",
            "88e53e775e6d470aa5ac3ad4d9d9a916",
            "437b3121a7c648aba5631506cd5182d5",
            "55dff5c4112c4cc4a47ae14c8e6c15e6",
            "3432e2907108416cabef4ada4d8b0efe",
            "ca0cf0a7f5864faab4e5d50f894272ca"
          ]
        },
        "outputId": "8976471f-d062-4b07-8738-485eb8613702"
      },
      "source": [
        "#load embedding model and start nadi model from scratch\n",
        "epoch_embed = 1\n",
        "model_nadi = Bert_Nadi_Task(load_model(model_embed,epoch_embed,\"embed\"))\n",
        "epoch_nadi = 4\n",
        "model_nadi = load_model(model_nadi,epoch_nadi,\"nadi\")\n",
        "model_nadi.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from Models/saved_embed_epoch1.txt\n",
            "Loading model from Models/saved_nadi_epoch4.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bert_Nadi_Task(\n",
              "  (bert): BertEmbedding(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (embedding2): Linear(in_features=768, out_features=32000, bias=True)\n",
              "  )\n",
              "  (norm): LayerNorm((32000,), eps=1e-12, elementwise_affine=True)\n",
              "  (tanh): Tanh()\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=32000, out_features=21, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sV5elXgjCuBK"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RhBdyTkXzmfR",
        "colab": {}
      },
      "source": [
        "labels = df_train.country_label.values\n",
        "#this is ordered unique list however it'll be changed if any row appended in dataset so use it as static if it doesn't match next line\n",
        "#labels_vocab = ['Iraq', 'Egypt', 'Morocco', 'Libya', 'United_Arab_Emirates', 'Mauritania', 'Saudi_Arabia', 'Bahrain', 'Syria', 'Djibouti', 'Lebanon', 'Oman', 'Palestine', 'Algeria', 'Somalia', 'Jordan', 'Tunisia', 'Kuwait', 'Yemen', 'Sudan', 'Qatar']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ej1PVIJYzmfW",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ef8a2512-ca03-4067-fde3-2f77356bc1e5"
      },
      "source": [
        "nadi_dataset = dataset_nadi(df_train.tweet_content.values,labels,labels_vocab,tokenizer,preprocess=Transform_preprocess(),transform=None)\n",
        "train_dataloader ,validation_dataloader = prepare_data(nadi_dataset,0.95,8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training samples 19950\n",
            "validation samples 1050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "igFJX1HXC6Zd"
      },
      "source": [
        "### Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UiA3ZjyMzmfn",
        "scrolled": false,
        "colab": {},
        "outputId": "df9deecd-ddd0-407e-c6b7-48047b2ed444"
      },
      "source": [
        "model_nadi,train_loss_nadi,valid_loss_nadi = training_model(model_nadi,'nadi',train_dataloader,validation_dataloader,epochs=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "19950/19950: [===============================>] - ETA 1.7ssss\n",
            "Saving model to ./saved_nadi_epoch1.txt\n",
            "Validation\n",
            "Validation Loss : 2.121380985234723\n",
            "Epoch: 2\n",
            "19950/19950: [===============================>] - ETA 0.3sss\n",
            "Saving model to ./saved_nadi_epoch2.txt\n",
            "Validation\n",
            "Validation Loss : 2.1113187239477127\n",
            "Epoch: 3\n",
            "19950/19950: [===============================>] - ETA 0.3sss\n",
            "Saving model to ./saved_nadi_epoch3.txt\n",
            "Validation\n",
            "Validation Loss : 2.2292832845088206\n",
            "Epoch: 4\n",
            "19950/19950: [===============================>] - ETA 0.3sss\n",
            "Saving model to ./saved_nadi_epoch4.txt\n",
            "Validation\n",
            "Validation Loss : 2.587091742139874\n",
            "Done\n",
            "Total training took : 0:57:24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b6vjkM3DD9_w"
      },
      "source": [
        "# Testing Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5VZofCgLFFHg"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LsWu37GPzmfp",
        "colab": {}
      },
      "source": [
        "def predict_model(model,prediction_dataloader,device):\n",
        "  model.eval()\n",
        "  predictions , true_labels = [], []\n",
        "  for batch in prediction_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    logits = outputs[1] \n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "  flat_predictions = np.concatenate(predictions, axis=0)\n",
        "  flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "  flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "  print('DONE.')\n",
        "  return flat_predictions,flat_true_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jjn8Et7Ezmfr",
        "colab": {}
      },
      "source": [
        "def show_predictions(test_dataset,predictions_items,labels_items,sentences,samples = 10):\n",
        "  true_predicted = 0 \n",
        "  for i in range(samples):\n",
        "    print(\"Sentence :\",sentences[i])\n",
        "    print(\"True label :\",test_dataset.idx2label[labels_items[i]])\n",
        "    print(\"predicted Label :\" , test_dataset.idx2label[predictions_items[i]])\n",
        "    print(\"\\n\")\n",
        "    if(predictions_items[i] == labels_items[i]):\n",
        "      true_predicted += 1\n",
        "  print(\"with number of samples =\",samples,\" true predicted = \",true_predicted, \" acc = \",(true_predicted*100.0/samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0da7W845zmf2",
        "colab": {}
      },
      "source": [
        "def show_score(epochs,flat_true_labels,flat_predictions):\n",
        "  #calculate accuracy for test data\n",
        "  print(\"for number of epochs = \",epochs)\n",
        "  print(\"Testing Accuracy using accuracy score=\",accuracy_score(flat_true_labels, flat_predictions))\n",
        "  print(\"Testing Accuracy using macro recall score=\",recall_score(flat_true_labels, flat_predictions, average='macro')) #average='micro' same for accuracy_score\n",
        "  print(\"Testing Accuracy using macro precision score=\",precision_score(flat_true_labels, flat_predictions ,average='macro')) #average='micro' same for accuracy_score\n",
        "  print(\"Testing Accuracy using macro f1 avg =\",f1_score(flat_true_labels, flat_predictions, average='macro')) #average='micro' same for accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "05DzcjTkFH1a"
      },
      "source": [
        "## Test Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D4-MLadiHv1v",
        "colab": {}
      },
      "source": [
        "sentences_test = df_test.tweet_content.values\n",
        "labels_test = df_test.country_label.values\n",
        "test_dataset = dataset_nadi(sentences_test,labels_test,labels_vocab,tokenizer,preprocess=Transform_preprocess())\n",
        "test_dataloader = DataLoader(test_dataset,sampler = RandomSampler(test_dataset),batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XjGpm10fzmfw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "2cb07c1a-cbac-4265-b7ac-136b243f0ed3"
      },
      "source": [
        "flat_predictions,flat_true_labels = predict_model(model_nadi,test_dataloader,device)\n",
        "show_score(4,flat_true_labels,flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE.\n",
            "for number of epochs =  4\n",
            "Testing Accuracy using accuracy score= 0.40205769618721\n",
            "Testing Accuracy using macro recall score= 0.23793407709999\n",
            "Testing Accuracy using macro precision score= 0.2547309267575428\n",
            "Testing Accuracy using macro f1 avg = 0.24051259820371235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mure9dwn5jSS",
        "colab_type": "code",
        "colab": {},
        "outputId": "13275a8c-c57f-4092-9d26-515e6f27a7d5"
      },
      "source": [
        "show_predictions(test_dataset,flat_predictions,flat_true_labels,sentences_test,samples = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence : @Osama__zahrani Ø§ÙŠØ³ÙƒÙˆ Ù„Ø§Ø¹Ø¨ Ø§Ù„ÙŠÙˆÙ… :) Ø§Ø³ÙŠØ³Øª ÙˆÙ‡Ø¯Ù\n",
            "True label : Libya\n",
            "predicted Label : Djibouti\n",
            "\n",
            "\n",
            "Sentence : Ø¨Ø¹Ø¯ ØµÙ„Ø§Ù‡ Ø§Ù„ÙØ¬Ø± Ø¨Ù‚Ø§\n",
            "True label : Algeria\n",
            "predicted Label : Algeria\n",
            "\n",
            "\n",
            "Sentence : Ø¥Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø© ÙŠÙƒÙˆÙ† Ù…Ù† Ù†ØµÙŠØ¨ÙŠ\n",
            "True label : Algeria\n",
            "predicted Label : Morocco\n",
            "\n",
            "\n",
            "Sentence : Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡ Ø®Ù„ÙŠ Ø§Ù„Ø³ÙˆØ¯Ø§Ù†ÙŠ ÙŠØ²ØºØ¨Ùƒ\n",
            "True label : Saudi_Arabia\n",
            "predicted Label : Iraq\n",
            "\n",
            "\n",
            "Sentence : ÙƒÙ„ Ø­Ø§Ø¬Ø© Ù…Ø­Ø³ÙˆØ¨Ø© ÙŠØ§ Ø¬Ù…Ø§Ø¹Ø© ÙˆØ§Ù„Ù„Ù‡\n",
            "True label : Qatar\n",
            "predicted Label : Saudi_Arabia\n",
            "\n",
            "\n",
            "Sentence : @kasimf Ø§Ù„Ù„Ù‡Ù… Ø¶ÙŠÙ‚ Ø¹Ù„ÙŠÙ‡ Ø£Ù†ÙØ§Ø³Ù‡ ÙˆØ¹Ø³Ø± Ù…ÙŠØªØªÙ‡ Ø¥Ù„Ù‰ Ø£Ø¬Ù„ Ù‡Ùˆ Ø¨Ø§Ù„ØºÙ‡..\n",
            "True label : Morocco\n",
            "predicted Label : Morocco\n",
            "\n",
            "\n",
            "Sentence : ÙŠØ¹Ù†ÙŠ Ù…Ø§ ÙŠØ­ØªØ§Ø¬ Ù†Ù„Ø¨Ø³ Ø«Ù‚ÙŠÙ„\n",
            "True label : Iraq\n",
            "predicted Label : Oman\n",
            "\n",
            "\n",
            "Sentence : (ÙˆÙ„Ø¦Ù† Ø³Ø£Ù„ØªÙ‡Ù… Ù…Ù† Ø®Ù„Ù‚Ù‡Ù… Ù„ÙŠÙ‚ÙˆÙ„Ù† Ø§Ù„Ù„Ù‡ ÙØ£Ù†Ù‰ ÙŠØ¤ÙÙƒÙˆÙ†) [Ø§Ù„Ø²Ø®Ø±Ù:87]\n",
            "True label : Morocco\n",
            "predicted Label : Tunisia\n",
            "\n",
            "\n",
            "Sentence : Ø¢Ø³ØªÙˆØ¯Ø¹Ùƒ ÙŠØ§ Ø±Ø¨ÙŠ Ø´Ø®ØµØ§Ù‹ ÙŠÙ†Ø¨Ø¶ ÙÙŠ Ù‚Ù„Ø¨ÙŠ ÙƒÙ„ Ù…Ø±Ù‡ ØŒ ÙˆÙ„Ø§ ÙŠÙØ§Ø±Ù‚ Ø¢ÙÙƒØ§Ø±ÙŠ\n",
            "True label : United_Arab_Emirates\n",
            "predicted Label : Egypt\n",
            "\n",
            "\n",
            "Sentence : Ù‚ÙÙ„ Ù„ÙÙ‘Ù† ÙŠÙØµÙÙŠØ¨ÙÙ†ÙØ§ Ø¥ÙÙ„ÙÙ‘Ø§ Ù…ÙØ§ ÙƒÙØªÙØ¨Ù Ø§Ù„Ù„ÙÙ‘Ù‡Ù Ù„ÙÙ†ÙØ§ Ù‡ÙÙˆÙ Ù…ÙÙˆÙ’Ù„ÙØ§Ù†ÙØ§ Ûš ÙˆÙØ¹ÙÙ„ÙÙ‰ Ø§Ù„Ù„ÙÙ‘Ù‡Ù ÙÙÙ„Ù’ÙŠÙØªÙÙˆÙÙƒÙÙ‘Ù„Ù Ø§Ù„Ù’Ù…ÙØ¤Ù’Ù…ÙÙ†ÙÙˆÙ†Ùpic.twitter.com/ZQU8TlVqs3\n",
            "True label : Jordan\n",
            "predicted Label : Libya\n",
            "\n",
            "\n",
            "with number of samples = 10  true predicted =  2  acc =  20.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o0M-I4aRHGFB"
      },
      "source": [
        "## Predict Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4vlm4tfXHeaI",
        "colab": {}
      },
      "source": [
        "sentences__ = ['Ø§Ø³ÙƒÙ†Ø¯Ø±ÙŠÙ‡','Ù…Ø¹ØªØ²']\n",
        "labels__ = ['Egypt','Oman']\n",
        "dataset__ = dataset_nadi(sentences__,labels__,labels_vocab,tokenizer)\n",
        "dataloader__ = DataLoader(dataset__,sampler = RandomSampler(dataset__),batch_size = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IW0q2Pg-zmf3",
        "colab": {},
        "outputId": "073f8744-b9bd-4cab-a1db-40273d550a7b"
      },
      "source": [
        "flat_predictions__,flat_true_labels__ = predict_model(model_nadi,dataloader__,device)\n",
        "show_predictions(dataset__,flat_predictions__,flat_true_labels__,sentences__,samples = len(sentences__))\n",
        "# show_score(4,flat_true_labels__,flat_predictions__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE.\n",
            "Sentence : Ø§Ø³ÙƒÙ†Ø¯Ø±ÙŠÙ‡\n",
            "True label : Egypt\n",
            "predicted Label : Egypt\n",
            "\n",
            "\n",
            "Sentence : Ù…Ø¹ØªØ²\n",
            "True label : Oman\n",
            "predicted Label : Libya\n",
            "\n",
            "\n",
            "with number of samples = 2  true predicted =  1  acc =  50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5unvPstz5jSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}